# 第十章 聚类和k均值聚类
对数据分类是一种常见分析方法，如果我们已知数据的类别并且已经给数据分好了类，那么我们可以利用分类方法（classification）进行分类。但是某些情况下，只有数据没有标签，我们怎么办。一个想法就是把相似的数据放到一起，这样就自然形成了几类。那么问题来了，什么样的数据是相似，也就是以什么样的标准定义相似度。直观的想法就是离的近的放一类呗，这就是用距离刻画相似度；或者相关系数大的方一起呗，这就是用相关系数刻画相似度。我们首先介绍这些度量。
## 10.1 标准
### 10.1.1 距离标准
z拿到数据第一反应一般是可视化，把数据处理为图像后，感觉聚类变得非常清晰——离得近的聚成一类。这就涉及到数据之间的距离。泛函分析里我们已经引入了距离公理，但聚类分析里的距离却不要求满足这些，我们记数据点$x=(x_1,x_2,...,x_n)$，以下是一些常用距离：

(i)欧氏距离，即L2范数：

$
d_{ij}^{(2)}=(\sum_{t=1}^n(x_i-x_j)^2)^{1/2}
$

(ii)Minkowski距离：

$
d_{ij}^{(q)}=(\sum_{t=1}^n|x_i-x_j|^q)^{1/q}
$

(iii)Chebyshev距离：

$
d_{ij}^{(c)}=\max\limits_{1\geq{t}\geq{p}}|x_{it}-x_{jt}|
$


