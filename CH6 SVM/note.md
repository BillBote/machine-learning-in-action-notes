## 第六章 SVM
SVM，即支持向量机(Support Vector Machines,SVM)，这个名字听起来很唬人啊，其实本质是一种二分类算法。我们都知道做二分类时会有很多种情况，SVM在所有可能的情况里选择间隔最大的。它最优秀的地方在于它可以和核技巧结合来成为非线性分类器。为了更好地理解SVM，我们从数学原理开始。

### 6.1原理
#### 6.1.1线性可分向量机
首先考虑最简单的情形，数据可分并且是线性可分的。也就是说在不做任何降维或者升维变换时，我们可以将两部分数据用一个超平面分开，并且平面方程有$wx=b$的形式。比如说二维数据，我们把所有数据点绘制到XY平面上，可以找到一条直线将它们分开。我们假设数据集为

$
T={(x_1,y_1),(x_2,y_2),...,(x_N,y_N)}
$

其中$x_i\in{R^n},y_i\in{\{+1,-1\}}$，我们用$y_i$来表示$x_i$的分类，即正负两类。目的是找到一个超平面$wx=b$使得$x_i$被分到它的两侧，这时候我们导出分类规则：

记$f(x)=sign(wx+b)$为线性可分向量机。

接下来要寻找间隔最大的分类规则，首先定义间隔，我们引入函数间隔和几何间隔。

##### 函数间隔
对与给的的训练数据集T和超平面(w,b)，定义超平面关于样本点$(x_i,y_i)$的函数间隔为

$
\hat{\gamma_i}=y_i(w·x_i+b),
$

超平面关于训练集的函数间隔为其关于各样本点的函数间隔的最小值

 $
 \hat{\gamma}=\min\limits_{i=1,...N}\hat{\gamma_i}
 $

函数间隔能比较好的表示分类预测时的正确性和确信度，但是存在一个问题，如果我们等倍数的放大w和b，超平面不变，函数间隔却被放大了。因此我们需要给函数间隔加一些约束，比如规定$||w||=1$，这时我们得到了几何间隔

##### 几何间隔
为了能使得$||w||=1$，我们将超平面中x的系数归一化，规定超平面(w,b)关于样本点$(x_i,y_i)$的几何间隔为

$
\gamma_i=y_i(\frac{w}{||w||}·x_i+\frac{b}{||w||})
$

超平面关于训集的几何间隔为其关于数据点间隔的最小值

$
\gamma=\min\limits_{i=1,...,N}\gamma_i
$

因此几何间隔和函数间隔有下面的关系

$
\gamma_i=\frac{\hat{\gamma_i}}{||w||},\gamma=\frac{\hat{\gamma}}{||w||}
$

上面我们以及获得了间隔的定义，接下来寻找使间隔最大化的平面即可，用数学式表达即为一个约束最优化问题

$
\max\limits_{w,b} \gamma

s.t.  y_i(\frac{w}{||w||}·x_i+\frac{b}{||w||})\geq{\gamma}, i=1,2,...,N
$

利用几何间隔和函数间隔的关系可以将问题改写为

$
\max\limits_{w,b} \frac{\hat{\gamma}}{||w||}

s.t. y_i(w·x_i+b)\geq{\hat{\gamma}}, i=1,2,...,N
$

观察发现，如果让w和b按比例变成$\lambda{w}$和$\lambda{b}$，函数间隔变成$\lambda\gamma$，对约束和最大化目标均没有影响。因此，为了简化问题，我们令$\hat{\gamma}=1$。将它带入原问题并且注意到最大化$\frac{1}{||w||}$和最小化$\frac{1}{2}||w||^2$一样，可以得到

$
\min\limits_{w,b} \frac{1}{2}||w||^2

s.t. y_i(w·x_i+b)-1\geq{0}
$

求出上述问题的解，即得到了最大间隔超平面，我们可以证明这个平面是唯一的（自己推）。

那么问题来了，为啥这个问题被称为支持向量机？在问题中，离超平面最近的点被称为支持向量，它们满足$y_i(w·x_i+b)-1=0$。不难理解只有支持向量决定了超平面的位置，因为如果移动支持向量之外的点，超平面不发生移动，但支持向量一旦发生变化，超平面必然改变，因此模型完全由支持向量决定，称之为支持向量机就不为过。

其具体的数学解法较为复杂，需要用到拉格朗日对偶算法，详见李航老师的统计学习方法。

#### 6.1.2 线性支持向量机
接下来考虑不可分的数据集，这种情况下上述约束不一定成立，需要修改条件使其能够进行间隔最大化，这时候的间隔最大化不同于上一节的最大化，是为软间隔最大化。我们同样假设训练集为$T=\{(x_1,y_1),(x_2,y_2),...,(x_N,y_N)\}$，由于各数据点不一定满足线性可分向量机的约束，可以引入松弛变量$\xi_i\geq{0}$，这样约束条件变成

$
y_i(w·x_i+b)\geq{1-\xi_i}
$

同时优化目标应该引入惩罚部分

$
\frac{1}{2}||w||^2+C\Sum_{i=1}^N\xi_i
$

C被称为惩罚参数，这样优化目标就有了两层含义：使间隔最大，并且让误分类的点最少。综合以下，问题就变成了

$
\min\limits_{w,b,\xi} \frac{1}{2}||w||^2+C\Sum_{i=1}^N\xi_i

s.t. y_i(w·x_i+b)\geq{1-\xi_i}, i=1,2,...,N

\xi_i\geq{0}, i=1,2,...,N
$

这样这个问题的最优解就是我们寻找的超平面。

#### 6.1.3非线性支持向量机和核函数




