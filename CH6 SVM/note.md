## 第六章 SVM
SVM，即支持向量机(Support Vector Machines,SVM)，这个名字听起来很唬人啊，其实本质是一种二分类算法。我们都知道做二分类时会有很多种情况，SVM在所有可能的情况里选择间隔最大的。它最优秀的地方在于它可以和核技巧结合来成为非线性分类器。为了更好地理解SVM，我们从数学原理开始。

### 6.1原理
#### 6.1.1线性可分向量机
首先考虑最简单的情形，数据可分并且是线性可分的。也就是说在不做任何降维或者升维变换时，我们可以将两部分数据用一个超平面分开，并且平面方程有$wx=b$的形式。比如说二维数据，我们把所有数据点绘制到XY平面上，可以找到一条直线将它们分开。我们假设数据集为

$
T={(x_1,y_1),(x_2,y_2),...,(x_N,y_N)}
$

其中$x_i\inR^n,y_i\in{+1,-1}$，我们用$y_i$来表示$x_i$的分类，即正负两类。目的是找到一个超平面$wx=b$使得$x_i$被分到它的两侧，这时候我们导出分类规则：

记$f(x)=sign(wx+b)$为线性可分向量机。

接下来要寻找间隔最大的分类规则，首先定义间隔，我们引入函数间隔和几何间隔。

##### 函数间隔
对与给的的训练数据集T和超平面(w,b)，定义超平面关于样本点$(x_i,y_i)$的函数间隔为

$
\hat{\gamma_i}=y_i(w·x_i+b),
$

超平面关于训练集的函数间隔为其关于各样本点的函数间隔的最小值

 $
 \hat{\gamma}=
 $
